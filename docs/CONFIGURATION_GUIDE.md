# SkillsMatch.AI - Configuration Guide

## Overview

SkillsMatch.AI uses environment variables and configuration files for flexible deployment across development, testing, and production environments.

## Table of Contents

1. [Environment Variables](#environment-variables)
2. [Configuration Files](#configuration-files)
3. [Development Setup](#development-setup)
4. [Production Setup](#production-setup)
5. [Docker Configuration](#docker-configuration)
6. [Advanced Configuration](#advanced-configuration)

## Environment Variables

### Core Configuration

Create `.env` file in project root with the following variables:

```bash
# Flask Application
FLASK_ENV=development              # development|production|testing
FLASK_DEBUG=False                  # Enable Flask debug mode
SECRET_KEY=your-secret-key-here   # CHANGE THIS IN PRODUCTION!
API_PORT=5000                      # API server port
API_HOST=127.0.0.1                # API server host (use 0.0.0.0 for external access)

# Database
DATABASE_URL=sqlite:///web/data/skillsmatch.db
# Or for PostgreSQL:
# DATABASE_URL=postgresql://user:password@localhost/skillsmatch_db

# Logging
LOG_LEVEL=INFO                     # DEBUG|INFO|WARNING|ERROR|CRITICAL
LOG_FILE=logs/skillsmatch.log      # Optional file path for logs
JSON_LOGGING=False                 # Use JSON format for logs (production)

# Cache Configuration
CACHE_TYPE=simple                  # simple|redis|memcached
CACHE_REDIS_URL=redis://localhost:6379/0
CACHE_DEFAULT_TIMEOUT=300          # Cache timeout in seconds

# AI Service Configuration
OPENAI_API_KEY=sk-...             # OpenAI API key
GITHUB_TOKEN=ghp_...              # GitHub token (for Models API fallback)
AZURE_OPENAI_KEY=...              # Azure OpenAI key (fallback)
AZURE_OPENAI_ENDPOINT=...         # Azure endpoint URL
AI_PROVIDER=github                 # github|openai|azure (priority order)

# External Services
CHROMA_COLLECTION_NAME=skillsmatch-vectors
VECTOR_DB_PATH=data/vector_db     # Path for vector database

# Security
CORS_ORIGINS=*                    # CORS allowed origins
RATE_LIMIT_ENABLED=True           # Enable rate limiting
RATE_LIMIT_PER_MINUTE=100         # Requests per minute per IP
```

### Variable Types & Validation

| Variable | Type | Valid Values | Default | Required |
|----------|------|--------------|---------|----------|
| `FLASK_ENV` | string | development, production, testing | development | No |
| `FLASK_DEBUG` | bool | true, false | false | No |
| `SECRET_KEY` | string | Any string (min 32 chars for production) | generated | No |
| `API_PORT` | int | 1-65535 | 5000 | No |
| `DATABASE_URL` | string | Valid DB URL | sqlite:/// | No |
| `LOG_LEVEL` | string | DEBUG, INFO, WARNING, ERROR, CRITICAL | INFO | No |
| `CACHE_TYPE` | string | simple, redis, memcached | simple | No |
| `OPENAI_API_KEY` | string | sk-* | None | No |
| `RATE_LIMIT_PER_MINUTE` | int | > 0 | 100 | No |

## Configuration Files

### web/config.py

Main Flask configuration module. Do not edit this file directly; use environment variables instead.

```python
# Example: To change log level
# Set: LOG_LEVEL=DEBUG
# web/config.py will automatically read this
```

### web/database/db_config.py

Database connection configuration. Manages SQLAlchemy session factory.

### web/config/ai_config.py

AI provider configuration with fallback chain:
1. GitHub Models API
2. OpenAI API
3. Azure OpenAI

## Development Setup

### Quick Start

```bash
# 1. Create environment
conda create -n smai python=3.11
conda activate smai

# 2. Install dependencies
pip install -r requirements.txt

# 3. Create .env file
cat > .env << 'EOF'
FLASK_ENV=development
FLASK_DEBUG=True
SECRET_KEY=dev-secret-key-change-in-production
LOG_LEVEL=DEBUG
OPENAI_API_KEY=sk-...
GITHUB_TOKEN=ghp_...
EOF

# 4. Initialize database
python init_sqlite.py

# 5. Run development server
python web/app.py
```

### .env.example

Use as template:

```bash
cp .env.example .env
# Edit .env with your values
nano .env
```

### Verify Configuration

```bash
# Check configuration is loaded correctly
python -c "
import os
from dotenv import load_dotenv
load_dotenv()
print('FLASK_ENV:', os.getenv('FLASK_ENV'))
print('LOG_LEVEL:', os.getenv('LOG_LEVEL'))
print('DATABASE_URL:', os.getenv('DATABASE_URL'))
"
```

## Production Setup

### Security Considerations

```bash
# 1. Generate strong SECRET_KEY
python -c "import secrets; print(secrets.token_hex(32))"
# Add to: SECRET_KEY=<generated-value>

# 2. Use PostgreSQL (not SQLite)
# DATABASE_URL=postgresql://user:password@prod-db.example.com/skillsmatch

# 3. Use Redis for caching
# CACHE_TYPE=redis
# CACHE_REDIS_URL=redis://prod-redis.example.com:6379/0

# 4. Enable JSON logging
# JSON_LOGGING=True

# 5. Set strict log level
# LOG_LEVEL=WARNING

# 6. Enable rate limiting
# RATE_LIMIT_ENABLED=True
```

### Production .env Example

```bash
# Flask
FLASK_ENV=production
FLASK_DEBUG=False
SECRET_KEY=<use-generated-strong-key>

# Database
DATABASE_URL=postgresql://user:password@prod-db.example.com/skillsmatch

# Logging
LOG_LEVEL=INFO
JSON_LOGGING=True
LOG_FILE=/var/log/skillsmatch/application.log

# Cache
CACHE_TYPE=redis
CACHE_REDIS_URL=redis://prod-redis.example.com:6379/0

# AI Services
OPENAI_API_KEY=sk-...
GITHUB_TOKEN=ghp_...

# Security
CORS_ORIGINS=https://skillsmatch.ai,https://www.skillsmatch.ai
RATE_LIMIT_ENABLED=True
RATE_LIMIT_PER_MINUTE=100
```

### Environment Validation

Create `check_production_config.sh`:

```bash
#!/bin/bash

echo "Checking production configuration..."

# Required variables
required_vars=(
    "SECRET_KEY"
    "DATABASE_URL"
    "OPENAI_API_KEY"
)

for var in "${required_vars[@]}"; do
    if [ -z "${!var}" ]; then
        echo "❌ Missing required variable: $var"
        exit 1
    fi
done

# Validate values
if [[ "$FLASK_ENV" != "production" ]]; then
    echo "❌ FLASK_ENV should be 'production'"
    exit 1
fi

if [[ ! "$SECRET_KEY" =~ ^[a-f0-9]{64}$ ]]; then
    echo "⚠️  SECRET_KEY should be 64-character hex string (generated with secrets module)"
fi

if [[ "$DATABASE_URL" == sqlite* ]]; then
    echo "⚠️  Using SQLite in production. PostgreSQL recommended."
fi

echo "✅ Production configuration validated!"
```

## Docker Configuration

### Environment in Docker

Pass environment variables to Docker:

```bash
docker run -e FLASK_ENV=production \
           -e SECRET_KEY=<secret> \
           -e DATABASE_URL=postgresql://... \
           -e OPENAI_API_KEY=sk-... \
           skillsmatch-ai:latest
```

### Docker Compose

```yaml
version: '3.8'

services:
  app:
    build: .
    environment:
      FLASK_ENV: production
      SECRET_KEY: ${SECRET_KEY}
      DATABASE_URL: postgresql://user:pass@db:5432/skillsmatch
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      CACHE_TYPE: redis
      CACHE_REDIS_URL: redis://redis:6379/0
    depends_on:
      - db
      - redis

  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: skillsmatch
      POSTGRES_USER: user
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - db_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data

volumes:
  db_data:
  redis_data:
```

## Advanced Configuration

### Custom Log Format

Edit `web/utils/logging_config.py`:

```python
# Modify ConsoleFormatter.format() for custom format
# Example: Add thread name, request ID, etc.
```

### Custom Cache Backend

```python
# web/config.py
if CACHE_TYPE == 'custom':
    from custom_cache import CustomCache
    CACHE = CustomCache(...)
```

### Database Connection Pooling

```bash
# For PostgreSQL with connection pooling
DATABASE_URL=postgresql+psycopg2://user:password@db:5432/skillsmatch?pool_size=20&pool_recycle=3600
```

### Feature Flags

```bash
# .env
FEATURE_AI_ANALYSIS=True
FEATURE_BATCH_MATCHING=True
FEATURE_ADVANCED_FILTERING=False
```

Use in code:

```python
import os

if os.getenv('FEATURE_BATCH_MATCHING') == 'True':
    # Enable batch matching endpoint
```

### Performance Tuning

```bash
# Database
DATABASE_POOL_SIZE=20
DATABASE_POOL_RECYCLE=3600
DATABASE_ECHO=False  # Set to True for query logging

# Cache
CACHE_DEFAULT_TIMEOUT=300
CACHE_KEY_PREFIX=skillsmatch_
CACHE_REDIS_SOCKET_CONNECT_TIMEOUT=5

# API
REQUEST_TIMEOUT=30
MAX_CONTENT_LENGTH=16777216  # 16MB max request size
```

### Multiple Environment Files

Use different `.env` files for different environments:

```bash
# Load specific environment
export ENV=production
source .env.${ENV}
python web/app.py

# Or automatically via python-dotenv
# python-dotenv automatically loads .env file if present
```

## Configuration Validation

### Automated Checks

```bash
# scripts/validate_config.py
python scripts/check_ai_config.py      # Check AI configuration
python scripts/check_smai_env.sh       # Check environment setup
```

### Manual Verification

```python
from web.config import Config
from web.database import db
from web.core.import_manager import ImportManager

# Verify config
print(f"Environment: {Config.FLASK_ENV}")
print(f"Database: {Config.SQLALCHEMY_DATABASE_URI}")
print(f"Cache: {Config.CACHE_TYPE}")

# Test database connection
try:
    db.engine.execute("SELECT 1")
    print("✅ Database connected")
except Exception as e:
    print(f"❌ Database error: {e}")

# Test imports
try:
    ImportManager.get_instance()
    print("✅ Import system working")
except Exception as e:
    print(f"❌ Import error: {e}")
```

## Environment-Specific Examples

### Development
```bash
FLASK_ENV=development
FLASK_DEBUG=True
LOG_LEVEL=DEBUG
DATABASE_URL=sqlite:///web/data/skillsmatch.db
CACHE_TYPE=simple
```

### Testing
```bash
FLASK_ENV=testing
FLASK_DEBUG=False
LOG_LEVEL=WARNING
DATABASE_URL=sqlite:///:memory:
CACHE_TYPE=simple
```

### Staging
```bash
FLASK_ENV=production
FLASK_DEBUG=False
LOG_LEVEL=INFO
DATABASE_URL=postgresql://user:pass@staging-db/skillsmatch
CACHE_TYPE=redis
CACHE_REDIS_URL=redis://staging-redis:6379/0
```

### Production
```bash
FLASK_ENV=production
FLASK_DEBUG=False
LOG_LEVEL=WARNING
JSON_LOGGING=True
DATABASE_URL=postgresql://user:pass@prod-db/skillsmatch
CACHE_TYPE=redis
CACHE_REDIS_URL=redis://prod-redis:6379/0
```

## Troubleshooting

### Configuration Not Loading

```bash
# Check if .env file exists
ls -la .env

# Verify environment variables are loaded
python -c "import os; from dotenv import load_dotenv; load_dotenv(); print(os.getenv('FLASK_ENV'))"

# Check for syntax errors in .env
python -c "import dotenv; dotenv.dotenv_values('.env')"
```

### Database Connection Issues

```bash
# Test connection string
sqlalchemy_url = "postgresql://user:pass@host/db"
from sqlalchemy import create_engine
engine = create_engine(sqlalchemy_url)
connection = engine.connect()
```

### API Key Issues

```bash
# Verify OpenAI key is valid
import openai
openai.api_key = os.getenv('OPENAI_API_KEY')
openai.Model.list()
```

---

**Last Updated**: January 18, 2026
**Configuration Version**: 1.0.0
**Maintained By**: SkillsMatch.AI Team
